{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from tic_tac_toe import TicTacToeEnv\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(state, action, turn):\n",
    "    state_, reward, done = env.move(state, action, 1)\n",
    "    if done:\n",
    "        return reward\n",
    "\n",
    "    possible_actions = env.possible_actions()\n",
    "    \n",
    "    if turn == 1:\n",
    "        max_value = -np.inf\n",
    "\n",
    "    if turn == 0:\n",
    "        max_value = np.inf\n",
    "\n",
    "    for i in possible_actions:\n",
    "        value = minimax(state_, i, abs(1-turn))\n",
    "        if turn == 1:\n",
    "            max_value = max(max_value, value)\n",
    "        else:\n",
    "            max_value = min(max_value, value)\n",
    "\n",
    "    return max_value\n",
    "\n",
    "def search(state):\n",
    "    board = state\n",
    "    max_value = -np.inf\n",
    "    max_action = None\n",
    "    for i in range(9):\n",
    "        value = minimax(board, i, 0)\n",
    "        if value > max_value:\n",
    "            max_action = i\n",
    "            max_value = value\n",
    "\n",
    "    return max_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, possible_actions, turn, player):\n",
    "        self.state = None\n",
    "        self.parent = parent\n",
    "        self.player = player\n",
    "        self.value = 0\n",
    "        self.visits = 0\n",
    "        self.children = [None for i in range(9)]\n",
    "        self.possible_actions = possible_actions\n",
    "        self.fully_expanded = False\n",
    "        self.updated_node = True\n",
    "        self.turn = turn\n",
    "        self.terminal = False\n",
    "\n",
    "    @property\n",
    "    def depth(self):\n",
    "        count = 0\n",
    "        node = self\n",
    "        while not node.parent is None:\n",
    "            count += 1\n",
    "            node = node.parent\n",
    "\n",
    "        return count\n",
    "\n",
    "    def expand(self, env, turn):\n",
    "        if self.fully_expanded or not self.updated_node:\n",
    "            print('the node is already fully expanded or its not updated')\n",
    "\n",
    "        state_1 = self.state.copy()\n",
    "        playa = self.player\n",
    "\n",
    "        for action in self.possible_actions:\n",
    "            self.state = state_1\n",
    "            next_state, reward, done = env.move(self.state, action, self.player, self.player)\n",
    "            next_possible_actions = self.possible_actions.copy()\n",
    "            next_possible_actions.remove(action)\n",
    "            \n",
    "            node = Node(self, next_possible_actions, self.turn, abs(1-playa))\n",
    "            if done or len(next_possible_actions) == 0:\n",
    "                node.terminal = True\n",
    "            node.state = next_state\n",
    "            node.updated_node = True\n",
    "            self.children[action] = node\n",
    "\n",
    "        self.player = playa\n",
    "        flag = False\n",
    "        for i in self.possible_actions:\n",
    "            if self.children[i] is None:\n",
    "                flag = True\n",
    "        if not flag:\n",
    "            self.fully_expanded = True\n",
    "\n",
    "    def choose_node(self, scalar):\n",
    "        if not self.fully_expanded:\n",
    "            print(self.__dict__)\n",
    "            print('its not expanded')\n",
    "\n",
    "        \n",
    "        if len(self.possible_actions) < 1:\n",
    "            print(self.depth, 'depth')\n",
    "\n",
    "        max_ucb = -np.inf\n",
    "        max_node = []\n",
    "        ucbs = []\n",
    "\n",
    "        for action in self.possible_actions:\n",
    "            child = self.children[action]\n",
    "            if child.visits > 0:\n",
    "                ucb = child.value / child.visits + scalar * math.sqrt(math.log(self.visits / child.visits))\n",
    "            else:\n",
    "                ucb = np.inf\n",
    "            ucbs.append(ucb)\n",
    "            if ucb > max_ucb:\n",
    "                max_ucb = ucb\n",
    "                max_node.append(child)\n",
    "\n",
    "        if len(max_node) == 0:\n",
    "            print(self.parent.possible_actions)\n",
    "            print(f'terminal:{self.terminal}')\n",
    "        return np.random.choice(max_node)\n",
    "\n",
    "    def choose_action(self, scalar):\n",
    "        max_ucb = -np.inf\n",
    "        max_action = []\n",
    "\n",
    "        for action in self.possible_actions:\n",
    "            child = self.children[action]\n",
    "            if child.visits > 0:\n",
    "                ucb = child.value / child.visits + scalar * math.sqrt(math.log(self.visits / child.visits))\n",
    "            else:\n",
    "                ucb = np.inf\n",
    "            if ucb > max_ucb:\n",
    "                max_ucb = ucb\n",
    "                max_action.append(action)\n",
    "\n",
    "        return np.random.choice(max_action)\n",
    "\n",
    "    def backpropogate(self, value):\n",
    "        node = self\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.value += value\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def search(self, init_state, turn):\n",
    "        possible_actions = self.env.possible_actions()\n",
    "        start_node = Node(None, possible_actions, turn, turn)\n",
    "        start_node.state = init_state\n",
    "\n",
    "        for alo in range(1000):\n",
    "            node = start_node\n",
    "\n",
    "            # traverse\n",
    "            if node.fully_expanded:\n",
    "                while node.fully_expanded:\n",
    "                    node = node.choose_node(1/math.sqrt(2))\n",
    "\n",
    "\n",
    "            node_terminaled = False\n",
    "            if node.terminal:\n",
    "                #print(node.state)\n",
    "                #print('terminaled')\n",
    "                action = node.parent.children.index(node)\n",
    "                _, reward, _  = self.env.move(node.parent.state, action, node.parent.player, node.parent.turn)\n",
    "                node.backpropogate(reward)\n",
    "                node_terminaled = True\n",
    "                continue\n",
    "\n",
    "            # expand\n",
    "            node.expand(self.env, turn)\n",
    "            node = node.choose_node(1)\n",
    "\n",
    "            if node.terminal and not node_terminaled:\n",
    "                #print('terminaled')\n",
    "                action = node.parent.children.index(node)\n",
    "                _, reward, _ = self.env.move(node.parent.state, action, node.parent.player, node.parent.turn)\n",
    "                node.backpropogate(reward)\n",
    "                continue\n",
    "\n",
    "            # rollout\n",
    "            player = node.player\n",
    "            done = False\n",
    "            possible_actions = node.possible_actions.copy()\n",
    "            state = node.state\n",
    "            while not done:\n",
    "                if len(possible_actions) > 0:\n",
    "                    #print(player, 'player')\n",
    "                    action = np.random.choice(possible_actions)\n",
    "                    state, reward, done = self.env.move(\n",
    "                        state,\n",
    "                        action,\n",
    "                        player,\n",
    "                        turn\n",
    "                    )\n",
    "                    #env.print_board(state)\n",
    "                    #if done:\n",
    "                        #print(reward)\n",
    "                    possible_actions.remove(action)\n",
    "\n",
    "                else:\n",
    "                    done = True\n",
    "                    reward = 0\n",
    "\n",
    "                if done:\n",
    "                    #print('backpropp')\n",
    "                    #env.print_board(state)\n",
    "                    node.backpropogate(reward)\n",
    "\n",
    "                player = abs(1-player)\n",
    "\n",
    "\n",
    "        print(start_node.value, start_node.visits)\n",
    "        return start_node.choose_action(1/math.sqrt(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEnv()\n",
    "agent = MCTS(env)\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-186 1000\n",
      "alo\n",
      "None\n",
      " 1 0 1 \n",
      " 1 0 # \n",
      " 0 1 # \n",
      "\n",
      "0 1000\n",
      "alo\n",
      "None\n",
      " 1 0 1 \n",
      " 1 0 0 \n",
      " 0 1 # \n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = agent.search(state, 1)\n",
    "state_, _, _, _ = env.step(action)\n",
    "env.print_board()\n",
    "action = agent.search(state_, 0)\n",
    "state_, _, _, _ = env.step(action)\n",
    "state = state_\n",
    "env.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7e37d037fc1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "np.random.choice([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
