# PPO-BaseLine
My implementation of PPO

Contents:

1.PPO-Discrete

2.Batch-Continuous PPO:

    sample:
    episode: 50, score: 215.0, high_score: 431.0,  average: 100.2
    episode: 51, score: 260.0, high_score: 431.0,  average: 103.33333333333333
    episode: 52, score: 511.0, high_score: 511.0,  average: 111.17307692307692
    episode: 53, score: 335.0, high_score: 511.0,  average: 115.39622641509433
    episode: 54, score: 206.0, high_score: 511.0,  average: 117.07407407407408
    episode: 55, score: 131.0, high_score: 511.0,  average: 117.32727272727273
    episode: 56, score: 305.0, high_score: 511.0,  average: 120.67857142857143
    episode: 57, score: 297.0, high_score: 511.0,  average: 123.7719298245614
    episode: 58, score: 284.0, high_score: 511.0,  average: 126.53448275862068
    episode: 59, score: 315.0, high_score: 511.0,  average: 129.72881355932202
    episode: 60, score: 93.0, high_score: 511.0,  average: 129.11666666666667
    episode: 61, score: 202.0, high_score: 511.0,  average: 130.31147540983608
    episode: 62, score: 185.0, high_score: 511.0,  average: 131.19354838709677
    episode: 63, score: 180.0, high_score: 511.0,  average: 131.96825396825398
    episode: 64, score: 192.0, high_score: 511.0,  average: 132.90625
    episode: 65, score: 313.0, high_score: 511.0,  average: 135.6769230769231


TODO:
1. make parallelized ppo-discrete
2. implement multiple collectors
